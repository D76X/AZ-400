
---

# Q012:

You have a web app that runs on Azure virtual machines in multiple Azure regions. 
The virtual machines are accessed by using the public IPv6 addresses assigned to 
their network adapters. 
The IPv6 addresses are NOT associated with DNS names.

You plan to use **Azure Traffic Manager** to **load balance requests** across all
instances of the web apps. You need to identify which Traffic Manager traffic 
distribution method supports targeting IPv6 addresses as its endpoints.

Which Traffic Manager traffic distribution method should you identify?

Select only one answer.

1. MultiValue
2. Performance
3. Priority
4. Weighted

---

1. MultiValue

MultiValue is the only Traffic Manager traffic distribution method that provides
the ability to specify the IPv4 and IPv6 addresses of its endpoints. 

All others, including Performance, Priority, and Weighted, require that the 
endpoints be designated as DNS names only.

---

[Examine Traffic Manager](https://learn.microsoft.com/en-gb/training/modules/implement-canary-releases-dark-launching/3-examine-traffic-manager)

To control traffic in Azure, you can use a component called Azure Traffic Manager.
It is a **DNS-based traffic load balancer** that enables you to distribute traffic optimally to 
services **across global Azure regions** while providing high availability and responsiveness.

Traffic Manager **uses DNS to direct client requests to the most appropriate service endpoint** 
**based on a traffic-routing method and the health** of the endpoints.

An **endpoint is an Internet-facing service** hosted inside or outside of Azure.

Traffic Manager is resilient to failure, including the breakdown of an entire Azure region. 

 Traffic Manager currently provides **six options to distribute traffic**:

 1. Priority:
 Select Priority when you want to use a primary service endpoint for all traffic 
 and provide backups if the primary or the backup endpoints are unavailable.

 2. Weighted:
 Select Weighted when you want to distribute traffic across a set of endpoints, 
 either evenly or according to weights, which you define.

 3. Performance:
 Select Performance when you have endpoints in different geographic locations, 
 and you want end users to use the "closest" endpoint for the lowest network latency.

 4. Geographic:
Select Geographic so that users are directed to specific endpoints (Azure, External, or Nested) 
**based on which geographic location their DNS query originates from**. It empowers Traffic Manager
customers to enable scenarios where knowing a user's geographic region and routing them based on 
that is necessary. 
Examples include following: 
 > **data sovereignty mandates**
 > localization of content & user experience 
 > measuring traffic from different regions.

 5. Subnet:
 Select the Subnet traffic-routing method to map sets of end-user IP address ranges to a specific
 endpoint within a Traffic Manager profile. The endpoint returned will be mapped for that request's
 source IP address when a request is received.

 6. Muntivalue
Select MultiValue for Traffic Manager profiles that can only have IPv4/IPv6 addresses as endpoints
**for example VMs that have IPv6 or IPv4 addresses aasigned to their network cards but these IPs 
are NOT associated with DNS names**. 
When a query is received for this profile, all healthy endpoints are returned.


---

# Q011:

You plan to create an Azure Pipelines release pipeline that will be used for 
blue-green deployments of a .NET Core application named App1. 
The code of App1 implements feature flags.

You need to identify which service to use as the Feature Manager for the 
feature flag management of App1. 
The solution must minimize administrative effort.

Which service should you identify?

Select only one answer.

1. Azure Advisor
2. Azure App Configuration
3. Azure Automation
4. Azure Logic Apps

---

2. Azure App Configuration

App Configuration provides built-in Feature Manager functionality. 

**Logic Apps** and **Azure Automation** can potentially be configured for 
feature flag management, but this requires more effort compared to App Configuration. 

**Azure Advisor** does not provide Feature Manager functionality.

---

[Describe feature toggle maintenance](https://learn.microsoft.com/en-gb/training/modules/implement-blue-green-deployment-feature-toggles/6-describe-feature-toggle-maintenance)  

A feature toggle is just code. And to be more specific, conditional code. 
**It adds complexity to the code and increases the technical debt**.
Be aware of that when you write them, and **clean up when you don't need them anymore**.
While feature flags **can be helpful, they can also introduce many issues of their own**.
The idea of a toggle is that **it's short-lived** and only stays in the software when it's
necessary to release it to the customers.

You can classify the different types of toggles based on two dimensions as described by Martin Fowler.
He states that you can look at the dimension of:
 1. how long a toggle should be in your codebase 
 2. how dynamic the toggle needs to be

### Planning feature flag lifecycles

**The most important thing is to remember that you need to remove the toggles from the software**.
If you don't do that, they'll become a form of technical debt if you keep them around for too long.
As soon as you introduce a feature flag, you've added to your overall technical debt.

Like other technical debt, they're easy to add, but the longer they're part of your code,
 the bigger the technical debt becomes because you've added scaffolding logic needed for
 the branching within the code.

**The cyclomatic complexity of your code keeps increasing as you add more feature flags**,
as the number of possible paths through the code increases.

**Using feature flags can make your code less solid and can also add these issues**:

> The code is harder to test effectively as the number of logical combinations increases.
> The code is harder to maintain because it's more complex.
> The code might even be less secure.
> It can be harder to duplicate problems when they're found.

A plan for managing the lifecycle of feature flags is critical. 
As soon as you add a flag, you need to plan for when it will be removed.

**Feature flags shouldn't be repurposed**. There have been high-profile failures because
teams decided to reuse an old flag that they thought was no longer part of the code for a
new purpose.

### Tooling for release flag management

The amount of effort required to manage feature flags shouldn't be underestimated. 
It's essential to consider using tooling that tracks:

> Which flags exist.
> Which flags are enabled in which environments, situations, or target customer categories.
> The plan for when the flags will be used in production.
> The plan for when the flags will be removed.

Azure App Configuration offers a Feature Manager. 
See: 

---

[Tutorial: Manage feature flags in Azure App Configuration](https://learn.microsoft.com/en-us/azure/azure-app-configuration/manage-feature-flags)  

You can store all feature flags in Azure App Configuration and administer them from a single place. App Configuration has a portal UI named Feature Manager that's designed specifically for feature flags. App Configuration also natively supports the .NET Core feature-flag data schema.

---

[Enable staged rollout of features for targeted audiences](https://learn.microsoft.com/en-us/azure/azure-app-configuration/howto-targetingfilter-aspnet-core)  

The `Microsoft.FeatureManagement` library includes `TargetingFilter`, which enables a feature flag 
for **a specified list of users and groups, or for a specified percentage of users**. 

> TargetingFilter is "sticky." 
This means that once an individual user receives a feature, they'll continue to see that feature
on all future requests. You can use `TargetingFilter` to enable a feature for: 
- a specific account during a demo 
- to progressively roll out new features to users in different groups or "rings," 
and much more.

---

[Use feature filters to enable conditional feature flags](https://learn.microsoft.com/en-us/azure/azure-app-configuration/howto-feature-filters-aspnet-core)

---

# Q010:

You have a project in Azure DevOps named Project1 that contains a build pipeline. 
The build pipeline generates an artifact and stores the artifact in Azure Repos.

You create a release pipeline in Project1.
You need to automatically execute the release pipeline whenever the build pipeline 
generates a new artifact.

What should you configure?

Select only one answer.

1. the default approver settings of the first stage of the release pipeline
2. the release gate settings of the first stage of the release pipeline
3. the service connection settings of an artifact in the build pipeline
4. the trigger settings of an artifact in the build pipeline

---

4. the trigger settings of an artifact in the build pipeline

**The trigger settings of an artifact in the build pipeline** allow you to
configure the automatic execution of the release pipeline whenever the build
pipeline generates a new artifact. 

**A service connection** is not required since the artifact is part of Azure Repos
for the same project. 

**The default approver settings** do not require explicit approvals, so they do not
need to be configured to automatically execute the release pipeline if the build 
pipeline artifact trigger is enabled. 

**The default release gate** settings allow for automatic stage execution, so they 
do not need to be configured to automatically execute the release pipeline if the build
pipeline artifact trigger is enabled.

---

[Explore release recommendations](https://learn.microsoft.com/en-gb/training/modules/explore-release-strategy-recommendations/)  
[Explore release approvals](https://learn.microsoft.com/en-gb/training/modules/explore-release-strategy-recommendations/4-explore-release-approvals)  

[Configure build completion triggers (classic) - Azure Pipelines | Microsoft Learn](https://learn.microsoft.com/en-gb/azure/devops/pipelines/process/pipeline-triggers-classic?view=azure-devops)  

- Add a build completion trigger:
In the classic editor, pipeline triggers are called build completion triggers. 
You can select any other build in the same project to be the triggering pipeline.
After you add a build completion trigger, select the triggering build.
example: `features/modules/*`

- Download artifacts from the triggering build
In many cases, you'll want to download artifacts from the triggering build. 
To do this:

> 1 Edit your build pipeline.
> 2 Add the Download Build Artifacts task to one of your jobs under Tasks.
> 3 For Download artifacts produced by, select Specific build.
> 4 Select the team Project that contains the triggering build pipeline.
> 5 Select the triggering Build pipeline.
> 6 Select When appropriate, download artifacts from the triggering build.
> 7:
Even though you specified that you want to download artifacts from the triggering build,
you must still select a value for Build. The option you choose here determines which
build will be the source of the artifacts whenever your triggered build is run because
of any other reason than BuildCompletion (e.g. Manual, IndividualCI, Schedule, and so on).

> 8 Specify the Artifact name and make sure it matches the name of the artifact published by the triggering build.
> 9 Specify the Destination directory to which you want to download the artifacts. 
For example: `$(Build.BinariesDirectory)`

---

# Q009:

You plan a versioning strategy for a NuGet package.
You need to implement a unique prerelease label based on the date and time of the package.
Which semantic versioning should you use?

Select only one answer.

1. a custom scheme
2. a generated script
3. $(Major).$(Minor).$(Patch).$(date:yyyyMMdd)
4. $(Major).$(Minor).$(rev:.r)

---

1. a custom scheme

In a **case where a unique label is required**, a custom scheme must be implemented
by using date and time as unique values. 

`$(Major).$(Minor).$(Patch).$(date:yyyyMMdd)` uses variables for major, minor, patch, and date. 
**It does not generate unique values**. 

A script can be used to generate the version in the build pipeline. 

`$(Major).$(Minor).$(rev:.r)` is a format of semantic versioning that uses variables. 
It does not generate unique values based on date and time.

---

[Publish NuGet packages with Pipeline tasks or the classic editor - Azure Pipelines | Microsoft Learn](https://learn.microsoft.com/en-gb/azure/devops/pipelines/artifacts/nuget?view=azure-devops&tabs=yaml#package-versioning)

Azure Pipelines and can be configured in your NuGet task as follows:

- Use the date and time (Classic): 
- byPrereleaseNumber (YAML):
Your package version is in the format: `Major.Minor.Patch-ci-datetime` 
where you have the flexibility to choose the values of your Major, Minor, and Patch.

- Use an environment variable (Classic): 
- byEnvVar (YAML). 
Your package version is set to the value of the environment variable you specify.

- Use the build number (Classic): 
- byBuildNumber (YAML). 
Your package version is set to the build number. Make sure you set your build number 
format under your pipeline Options to: 
`$(BuildDefinitionName)_$(Year:yyyy).$(Month).$(DayOfMonth)$(Rev:.r)`. 

To do set the format in YAML, add a property `name`: 
at the root of your pipeline and add your format.

---

# Q008:

You have a project in Azure DevOps that contains build and release pipelines.
You need to change the number of parallel jobs that will be available to the 
agent pool allocated to the project.

At which level should you add the parallel jobs?

Select only one answer.

1. build pipeline
2. organization
3. project
4. release pipeline

---

2. organization

Parallel jobs are added at the organization level, 
not the project, build pipeline, or release pipeline levels.

---

[Configure and pay for parallel jobs](https://learn.microsoft.com/en-gb/azure/devops/pipelines/licensing/concurrent-jobs?view=azure-devops&tabs=ms-hosted)  
[Understand parallel jobs](https://learn.microsoft.com/en-gb/training/modules/describe-pipelines-concurrency/2-understand-parallel-jobs)  
[Estimate parallel jobs](https://learn.microsoft.com/en-gb/training/modules/describe-pipelines-concurrency/3-estimate-parallel-jobs)  

A simple rule of thumb: 
Estimate that you'll need one parallel job for every four to five users in your organization.

---

# Q007:

You plan to create a project in Azure DevOps.
You need to identify which Azure DevOps feature enables the sharing of arbitrary
values across all the definitions in the project.
Which Azure DevOps feature should you identify?

Select only one answer.

1. predefined variables
2. release pipeline variables
3. stage variables
4. variable groups

---

4. variable groups

Variable groups provide the ability to share arbitrary values across
all the definitions in the same project. 

The values of **predefined variables** are assigned automatically. 
**stage and pipeline variables** have a smaller scope than the entire project.

---

[Explore variables in release pipelines](https://learn.microsoft.com/en-gb/training/modules/manage-modularize-tasks-templates/4-explore-variables-release-pipelines)  
[Publish NuGet packages with Azure Pipelines (YAML/Classic)](https://learn.microsoft.com/en-gb/azure/devops/pipelines/artifacts/nuget?view=azure-devops&tabs=yaml)  

---

# Q006:

You have a project in Azure DevOps that uses packages from NuGet and Maven public registries.
You need to verify that project-level package feeds use original packages rather than copies.
Which Azure Artifacts feature should you implement?

Select only one answer.

1. public feeds
2. security policies
3. upstream sources
4. WinDbg

---

3. upstream sources

One of the advantages of **upstream sources is the control over which package is downloaded**, 
allowing you to verify that project-level package feeds use original packages. 

**Public feeds** are used to show and control packages, **but upstream sources are not allowed**. 

**A security policy** is used inside of a project-scoped feed, allowing you to control how you 
can access the feed, but does not provide public registry access or control. 

**To debug Azure Artifacts** by using symbol servers, you can use `WinDbg`. 
This feature does not provide upstream source control.

---

[Upstream sources overview - Azure Artifacts | Microsoft Learn](https://learn.microsoft.com/en-gb/azure/devops/artifacts/concepts/upstream-sources?view=azure-devops#advantages)

Enabling upstream sources offers several advantages for managing your product's dependencies within a single feed:

- Simplicity: 
When you publish all your packages to a single feed, it simplifies your configuration files like 
`NuGet.config, npmrc, or settings.xml`. With just one feed in your config file, you reduce the chances of errors 
and bugs, streamlining your setup.

- Determinism: 
your feed resolves package requests in order, resulting in more consistency when rebuilding your code.

- Provenance: 
Your feed retains information about the packages it saved from upstream sources. This allows you to verify 
that you're using the original package and not a copy or a potentially malicious version.

- Peace of mind: 
Every package installed from upstream sources is automatically saved to your feed. This means that even if
the upstream source is disabled, removed, or undergoing maintenance, you can continue developing and building
with confidence because you have a copy of that package in your feed.

---

[Configure upstream behavior](https://learn.microsoft.com/en-gb/azure/devops/artifacts/concepts/upstream-behavior?view=azure-devops&tabs=nuget%2Cget)  
[Training: Explore package dependencies](https://learn.microsoft.com/en-gb/training/modules/explore-package-dependencies/)
---


# Q005:

Your company plans to implement Azure Artifacts.
The company intends to use public and internal npm packages.
You need to recommend a method of creating separate groupings of public 
and private npm packages without the risk of name collisions.

What should you recommend?

1. audit
2. npm publish
3. NPMRC
4. scopes

---

4. scopes

**Scopes allow you to group npm packages**. 

**Audits** scan npm packages, but they do not group them. 

**NPMRC** is a file used to provide npm configuration settings. 

The **npm publish** command is used to upload packages to the feed 
and make the feed available for consumption.

---

[Use Npm scopes in Azure Artifacts](https://learn.microsoft.com/en-gb/azure/devops/artifacts/npm/scopes?view=azure-devops)  
Npm scopes serve as a means to categorize related packages into groups.
hese scopes enable you to create packages with identical names to those created 
by different users without encountering conflicts.
By using scopes, you have the **ability to segregate public and private packages** 
by adding the **scope prefix** `@scopeName` **and configuring the .npmrc file** 
to exclusively use a feed with that particular scope.

**Azure Artifacts** provides the capability to publish and download both scoped 
and nonscoped packages from feeds or public registries. 

> Use Cases
Npm scopes are particularly valuable when working with self-hosted on-premises 
servers lacking internet access, as configuring upstream sources in such scenarios
isn't feasible.  

 > We don't have to worry about name collisions.
 > No need to change the npm registry in order to install or publish our packages.
 > Each npm organization/user has their own scope, and only the owner or the scope members can publish packages to their scope.

---

# Q004:

You are creating an Azure Artifacts artifact.
You need to provide assurances of backward compatibility.
Which element of semantic versioning should you use?

1. label
2. major
3. minor
4. patch

---

4. patch
**A patch element is the only answer that provides assurances** of backward compatibility. 
Other answer choices either do not convey versioning, such as label, or do not provide any
assurances of backward compatibility.

---

# Q003: 

You plan a dependency management solution for a software package for your company.
You need to recommend which element of semantic versioning to use to designate a 
beta prerelease of the software package.
Which element of semantic versioning should you recommend?

Select only one answer.

1. label
2. major
3. minor
4. patch

---

1. label

**A label** element represents prereleases, such as alpha/beta. 

**A major** element represents a version of content that changed significantly, 
which results in some degree of incompatibility with the previous major version. 

**A minor** element represents a version of content that changed but not as 
significantly as the major version, **making it more likely** to be compatible 
with the previous minor version. 

**A patch** element represents a fix that preserves backward compatibility.

---

# Q002: 

You have a project in Azure DevOps named Project1 that contains a continuous integration pipeline named Pipeline1.
You plan to **use Windows-based self-hosted agents for UI tests in Pipeline1**.
You need to identify the option you must configure to apply to the agents.
Which option should you identify?

1. Enable Autologon.
2. Run a screen resolution task.
3. Run a unit test.
4. Run tests in parallel.

---

1. Enable Autologon.

When **self-hosted agents are used, autologon must be enabled** to allow UI tests to run. 

**A screen resolution task** allows additional configurations to be performed**, 
but an autologon configuration is needed first to allow the test to run. 

To **reduce the duration of the test activities**, running tests in parallel can be useful, 
but this strategy does not address this scenario. 

A unit test is the first step to adding testing to the development process.

---

# Q001: 

You plan to design a DevSecOps security validation process for your company.
You need to identify which stage in the process will include an automated Open Source Software (OSS) vulnerability scan.
Which stage should you identify?

1. continuous deployment
2. continuous integration
3. IDE/pull requests
4. nightly test runs

---

2. continuous integration
Continuous integration should include an OSS vulnerability scan. 
The integrated development environment/pull request step should include static code analysis and code reviews. 
Nightly test runs should include an infrastructure scan. 
Continuous deployment should include passive penetration tests, an SSL scan, and an infrastructure scan.

| Stage        | Scans Types     |
| ------------ | --------------- |
|  IDE/PR      | static code analysis and code reviews  |
|  CI          | OSS vulnerability scan  |
|  Nightly     | infrastructure scan  |
|  CD          | passive penetration tests, an SSL scan, and an infrastructure scan  |

---

[VERACODE - What are SSL and TLS Vulnerabilities?](https://www.veracode.com/security/ssl-tls-vulnerabilities)

The SSL Scanner uses testssl.sh, a command-line tool that checks a server’s service 
on any port to support TLS/SSL ciphers, protocols as well as recent cryptographic 
flaws, and more.
All issues found are further deciphered by our SSL Scanner and appropriately designed 
into a comprehensible report.

---

