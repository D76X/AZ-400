
---

# Q010:

You have a project in Azure DevOps named Project1 that contains a build pipeline. The build pipeline generates an artifact and stores the artifact in Azure Repos.

You create a release pipeline in Project1.

You need to automatically execute the release pipeline whenever the build pipeline generates a new artifact.

What should you configure?

Select only one answer.

the default approver settings of the first stage of the release pipeline

the release gate settings of the first stage of the release pipeline

the service connection settings of an artifact in the build pipeline

the trigger settings of an artifact in the build pipeline

---

# Q009:

You plan a versioning strategy for a NuGet package.
You need to implement a unique prerelease label based on the date and time of the package.
Which semantic versioning should you use?

Select only one answer.

1. a custom scheme
2. a generated script
3. $(Major).$(Minor).$(Patch).$(date:yyyyMMdd)
4. $(Major).$(Minor).$(rev:.r)

---

1. a custom scheme

In a **case where a unique label is required**, a custom scheme must be implemented
by using date and time as unique values. 

`$(Major).$(Minor).$(Patch).$(date:yyyyMMdd)` uses variables for major, minor, patch, and date. 
**It does not generate unique values**. 

A script can be used to generate the version in the build pipeline. 

`$(Major).$(Minor).$(rev:.r)` is a format of semantic versioning that uses variables. 
It does not generate unique values based on date and time.

---

[Publish NuGet packages with Pipeline tasks or the classic editor - Azure Pipelines | Microsoft Learn](https://learn.microsoft.com/en-gb/azure/devops/pipelines/artifacts/nuget?view=azure-devops&tabs=yaml#package-versioning)

Azure Pipelines and can be configured in your NuGet task as follows:

- Use the date and time (Classic): 
- byPrereleaseNumber (YAML):
Your package version is in the format: `Major.Minor.Patch-ci-datetime` 
where you have the flexibility to choose the values of your Major, Minor, and Patch.

- Use an environment variable (Classic): 
- byEnvVar (YAML). 
Your package version is set to the value of the environment variable you specify.

- Use the build number (Classic): 
- byBuildNumber (YAML). 
Your package version is set to the build number. Make sure you set your build number 
format under your pipeline Options to: 
`$(BuildDefinitionName)_$(Year:yyyy).$(Month).$(DayOfMonth)$(Rev:.r)`. 

To do set the format in YAML, add a property `name`: 
at the root of your pipeline and add your format.

---

# Q008:

You have a project in Azure DevOps that contains build and release pipelines.
You need to change the number of parallel jobs that will be available to the 
agent pool allocated to the project.

At which level should you add the parallel jobs?

Select only one answer.

1. build pipeline
2. organization
3. project
4. release pipeline

---

2. organization

Parallel jobs are added at the organization level, 
not the project, build pipeline, or release pipeline levels.

---

[Configure and pay for parallel jobs](https://learn.microsoft.com/en-gb/azure/devops/pipelines/licensing/concurrent-jobs?view=azure-devops&tabs=ms-hosted)  
[Understand parallel jobs](https://learn.microsoft.com/en-gb/training/modules/describe-pipelines-concurrency/2-understand-parallel-jobs)  
[Estimate parallel jobs](https://learn.microsoft.com/en-gb/training/modules/describe-pipelines-concurrency/3-estimate-parallel-jobs)  

A simple rule of thumb: 
Estimate that you'll need one parallel job for every four to five users in your organization.

---

# Q007:

You plan to create a project in Azure DevOps.
You need to identify which Azure DevOps feature enables the sharing of arbitrary
values across all the definitions in the project.
Which Azure DevOps feature should you identify?

Select only one answer.

1. predefined variables
2. release pipeline variables
3. stage variables
4. variable groups

---

4. variable groups

Variable groups provide the ability to share arbitrary values across
all the definitions in the same project. 

The values of **predefined variables** are assigned automatically. 
**stage and pipeline variables** have a smaller scope than the entire project.

---

[Explore variables in release pipelines](https://learn.microsoft.com/en-gb/training/modules/manage-modularize-tasks-templates/4-explore-variables-release-pipelines)  
[Publish NuGet packages with Azure Pipelines (YAML/Classic)](https://learn.microsoft.com/en-gb/azure/devops/pipelines/artifacts/nuget?view=azure-devops&tabs=yaml)  

---

# Q006:

You have a project in Azure DevOps that uses packages from NuGet and Maven public registries.
You need to verify that project-level package feeds use original packages rather than copies.
Which Azure Artifacts feature should you implement?

Select only one answer.

1. public feeds
2. security policies
3. upstream sources
4. WinDbg

---

3. upstream sources

One of the advantages of **upstream sources is the control over which package is downloaded**, 
allowing you to verify that project-level package feeds use original packages. 

**Public feeds** are used to show and control packages, **but upstream sources are not allowed**. 

**A security policy** is used inside of a project-scoped feed, allowing you to control how you 
can access the feed, but does not provide public registry access or control. 

**To debug Azure Artifacts** by using symbol servers, you can use `WinDbg`. 
This feature does not provide upstream source control.

---

[Upstream sources overview - Azure Artifacts | Microsoft Learn](https://learn.microsoft.com/en-gb/azure/devops/artifacts/concepts/upstream-sources?view=azure-devops#advantages)

Enabling upstream sources offers several advantages for managing your product's dependencies within a single feed:

- Simplicity: 
When you publish all your packages to a single feed, it simplifies your configuration files like 
`NuGet.config, npmrc, or settings.xml`. With just one feed in your config file, you reduce the chances of errors 
and bugs, streamlining your setup.

- Determinism: 
your feed resolves package requests in order, resulting in more consistency when rebuilding your code.

- Provenance: 
Your feed retains information about the packages it saved from upstream sources. This allows you to verify 
that you're using the original package and not a copy or a potentially malicious version.

- Peace of mind: 
Every package installed from upstream sources is automatically saved to your feed. This means that even if
the upstream source is disabled, removed, or undergoing maintenance, you can continue developing and building
with confidence because you have a copy of that package in your feed.

---

[Configure upstream behavior](https://learn.microsoft.com/en-gb/azure/devops/artifacts/concepts/upstream-behavior?view=azure-devops&tabs=nuget%2Cget)  
[Training: Explore package dependencies](https://learn.microsoft.com/en-gb/training/modules/explore-package-dependencies/)
---


# Q005:

Your company plans to implement Azure Artifacts.
The company intends to use public and internal npm packages.
You need to recommend a method of creating separate groupings of public 
and private npm packages without the risk of name collisions.

What should you recommend?

1. audit
2. npm publish
3. NPMRC
4. scopes

---

4. scopes

**Scopes allow you to group npm packages**. 

**Audits** scan npm packages, but they do not group them. 

**NPMRC** is a file used to provide npm configuration settings. 

The **npm publish** command is used to upload packages to the feed 
and make the feed available for consumption.

---

[Use Npm scopes in Azure Artifacts](https://learn.microsoft.com/en-gb/azure/devops/artifacts/npm/scopes?view=azure-devops)  
Npm scopes serve as a means to categorize related packages into groups.
hese scopes enable you to create packages with identical names to those created 
by different users without encountering conflicts.
By using scopes, you have the **ability to segregate public and private packages** 
by adding the **scope prefix** `@scopeName` **and configuring the .npmrc file** 
to exclusively use a feed with that particular scope.

**Azure Artifacts** provides the capability to publish and download both scoped 
and nonscoped packages from feeds or public registries. 

> Use Cases
Npm scopes are particularly valuable when working with self-hosted on-premises 
servers lacking internet access, as configuring upstream sources in such scenarios
isn't feasible.  

 > We don't have to worry about name collisions.
 > No need to change the npm registry in order to install or publish our packages.
 > Each npm organization/user has their own scope, and only the owner or the scope members can publish packages to their scope.

---

# Q004:

You are creating an Azure Artifacts artifact.
You need to provide assurances of backward compatibility.
Which element of semantic versioning should you use?

1. label
2. major
3. minor
4. patch

---

4. patch
**A patch element is the only answer that provides assurances** of backward compatibility. 
Other answer choices either do not convey versioning, such as label, or do not provide any
assurances of backward compatibility.

---

# Q003: 

You plan a dependency management solution for a software package for your company.
You need to recommend which element of semantic versioning to use to designate a 
beta prerelease of the software package.
Which element of semantic versioning should you recommend?

Select only one answer.

1. label
2. major
3. minor
4. patch

---

1. label

**A label** element represents prereleases, such as alpha/beta. 

**A major** element represents a version of content that changed significantly, 
which results in some degree of incompatibility with the previous major version. 

**A minor** element represents a version of content that changed but not as 
significantly as the major version, **making it more likely** to be compatible 
with the previous minor version. 

**A patch** element represents a fix that preserves backward compatibility.

---

# Q002: 

You have a project in Azure DevOps named Project1 that contains a continuous integration pipeline named Pipeline1.
You plan to **use Windows-based self-hosted agents for UI tests in Pipeline1**.
You need to identify the option you must configure to apply to the agents.
Which option should you identify?

1. Enable Autologon.
2. Run a screen resolution task.
3. Run a unit test.
4. Run tests in parallel.

---

1. Enable Autologon.

When **self-hosted agents are used, autologon must be enabled** to allow UI tests to run. 

**A screen resolution task** allows additional configurations to be performed**, 
but an autologon configuration is needed first to allow the test to run. 

To **reduce the duration of the test activities**, running tests in parallel can be useful, 
but this strategy does not address this scenario. 

A unit test is the first step to adding testing to the development process.

---

# Q001: 

You plan to design a DevSecOps security validation process for your company.
You need to identify which stage in the process will include an automated Open Source Software (OSS) vulnerability scan.
Which stage should you identify?

1. continuous deployment
2. continuous integration
3. IDE/pull requests
4. nightly test runs

---

2. continuous integration
Continuous integration should include an OSS vulnerability scan. 
The integrated development environment/pull request step should include static code analysis and code reviews. 
Nightly test runs should include an infrastructure scan. 
Continuous deployment should include passive penetration tests, an SSL scan, and an infrastructure scan.

| Stage        | Scans Types     |
| ------------ | --------------- |
|  IDE/PR      | static code analysis and code reviews  |
|  CI          | OSS vulnerability scan  |
|  Nightly     | infrastructure scan  |
|  CD          | passive penetration tests, an SSL scan, and an infrastructure scan  |

---

[VERACODE - What are SSL and TLS Vulnerabilities?](https://www.veracode.com/security/ssl-tls-vulnerabilities)

The SSL Scanner uses testssl.sh, a command-line tool that checks a server’s service 
on any port to support TLS/SSL ciphers, protocols as well as recent cryptographic 
flaws, and more.
All issues found are further deciphered by our SSL Scanner and appropriately designed 
into a comprehensible report.

---

